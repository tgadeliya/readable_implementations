{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=0)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=0)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "from readable_implementations.utils import Trainer\n",
    "from readable_implementations.utils.config import BasicConfig\n",
    "\n",
    "net = Net()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "config = BasicConfig(\n",
    "    device = \"cpu\",\n",
    "    model = net,\n",
    "    optimizer=optimizer,\n",
    "    loss_fn=criterion,\n",
    "    max_epochs=2,\n",
    "    train_dataloader=trainloader,\n",
    "    val_dataloader=testloader,\n",
    "    validate_every_batch= 6000,\n",
    ")\n",
    "\n",
    "trainer = Trainer(config)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:E:1 (4%), step=500, loss=0.576                     \n",
      "INFO:train:E:1 (8%), step=1000, loss=0.575                    \n",
      "INFO:train:E:1 (12%), step=1500, loss=0.573                    \n",
      "INFO:train:E:1 (16%), step=2000, loss=0.547                    \n",
      "INFO:train:E:1 (20%), step=2500, loss=0.503                    \n",
      "INFO:train:E:1 (24%), step=3000, loss=0.494                    \n",
      "INFO:train:E:1 (28%), step=3500, loss=0.469                    \n",
      "INFO:train:E:1 (32%), step=4000, loss=0.442                    \n",
      "INFO:train:E:1 (36%), step=4500, loss=0.435                    \n",
      "INFO:train:E:1 (40%), step=5000, loss=0.430                    \n",
      "INFO:train:E:1 (44%), step=5500, loss=0.417                    \n",
      " Epoch 0:  48%|████▊     | 5986/12500 [00:18<00:18, 351.39it/s]\n",
      "validation:   0%|          | 0/2500 [00:00<?, ?it/s]\u001B[A\n",
      "validation:   2%|▏         | 48/2500 [00:00<00:05, 469.28it/s]\u001B[A\n",
      "validation:   4%|▍         | 95/2500 [00:00<00:05, 453.80it/s]\u001B[A\n",
      "validation:   6%|▌         | 144/2500 [00:00<00:05, 468.11it/s]\u001B[A\n",
      "validation:   8%|▊         | 192/2500 [00:00<00:04, 472.37it/s]\u001B[A\n",
      "validation:  10%|█         | 252/2500 [00:00<00:04, 517.55it/s]\u001B[A\n",
      "validation:  12%|█▏        | 307/2500 [00:00<00:04, 526.79it/s]\u001B[A\n",
      "validation:  14%|█▍        | 360/2500 [00:00<00:04, 502.26it/s]\u001B[A\n",
      "validation:  16%|█▋        | 411/2500 [00:00<00:04, 464.18it/s]\u001B[A\n",
      "validation:  18%|█▊        | 459/2500 [00:00<00:04, 450.84it/s]\u001B[A\n",
      "validation:  20%|██        | 505/2500 [00:01<00:04, 428.59it/s]\u001B[A\n",
      "validation:  22%|██▏       | 549/2500 [00:01<00:04, 406.86it/s]\u001B[A\n",
      "validation:  24%|██▍       | 602/2500 [00:01<00:04, 438.82it/s]\u001B[A\n",
      "validation:  26%|██▌       | 656/2500 [00:01<00:03, 466.35it/s]\u001B[A\n",
      "validation:  29%|██▊       | 713/2500 [00:01<00:03, 494.84it/s]\u001B[A\n",
      "validation:  31%|███       | 772/2500 [00:01<00:03, 520.75it/s]\u001B[A\n",
      "validation:  33%|███▎      | 834/2500 [00:01<00:03, 548.15it/s]\u001B[A\n",
      "validation:  36%|███▌      | 900/2500 [00:01<00:02, 579.87it/s]\u001B[A\n",
      "validation:  39%|███▊      | 966/2500 [00:01<00:02, 602.07it/s]\u001B[A\n",
      "validation:  41%|████      | 1030/2500 [00:02<00:02, 612.81it/s]\u001B[A\n",
      "validation:  44%|████▍     | 1103/2500 [00:02<00:02, 645.69it/s]\u001B[A\n",
      "validation:  47%|████▋     | 1173/2500 [00:02<00:02, 660.95it/s]\u001B[A\n",
      "validation:  50%|████▉     | 1241/2500 [00:02<00:01, 663.72it/s]\u001B[A\n",
      "validation:  52%|█████▏    | 1311/2500 [00:02<00:01, 673.83it/s]\u001B[A\n",
      "validation:  55%|█████▌    | 1379/2500 [00:02<00:01, 671.54it/s]\u001B[A\n",
      "validation:  58%|█████▊    | 1447/2500 [00:02<00:01, 664.12it/s]\u001B[A\n",
      "validation:  61%|██████    | 1516/2500 [00:02<00:01, 669.43it/s]\u001B[A\n",
      "validation:  63%|██████▎   | 1584/2500 [00:02<00:01, 670.15it/s]\u001B[A\n",
      "validation:  66%|██████▌   | 1652/2500 [00:02<00:01, 670.31it/s]\u001B[A\n",
      "validation:  69%|██████▉   | 1720/2500 [00:03<00:01, 665.34it/s]\u001B[A\n",
      "validation:  71%|███████▏  | 1787/2500 [00:03<00:01, 659.23it/s]\u001B[A\n",
      "validation:  74%|███████▍  | 1853/2500 [00:03<00:00, 658.39it/s]\u001B[A\n",
      "validation:  77%|███████▋  | 1920/2500 [00:03<00:00, 659.44it/s]\u001B[A\n",
      "validation:  79%|███████▉  | 1986/2500 [00:03<00:00, 633.28it/s]\u001B[A\n",
      "validation:  82%|████████▏ | 2052/2500 [00:03<00:00, 638.64it/s]\u001B[A\n",
      "validation:  85%|████████▍ | 2118/2500 [00:03<00:00, 642.19it/s]\u001B[A\n",
      "validation:  87%|████████▋ | 2185/2500 [00:03<00:00, 648.63it/s]\u001B[A\n",
      "validation:  90%|█████████ | 2250/2500 [00:03<00:00, 648.51it/s]\u001B[A\n",
      "validation:  93%|█████████▎| 2316/2500 [00:03<00:00, 651.31it/s]\u001B[A\n",
      "validation:  95%|█████████▌| 2384/2500 [00:04<00:00, 657.66it/s]\u001B[A\n",
      "validation: 100%|██████████| 2500/2500 [00:04<00:00, 590.19it/s]\u001B[A\n",
      "INFO:train:Validation at 24000 step: acc: 0.41 , f1-macro: 0.38 , f1-micro: 0.38 , val_loss: 1.62\n",
      "INFO:train:E:1 (48%), step=6000, loss=0.419                    \n",
      "INFO:train:E:1 (52%), step=6500, loss=0.411                    \n",
      "INFO:train:E:1 (56%), step=7000, loss=0.402                    \n",
      "INFO:train:E:1 (60%), step=7500, loss=0.390                    \n",
      "INFO:train:E:1 (64%), step=8000, loss=0.386                    \n",
      "INFO:train:E:1 (68%), step=8500, loss=0.379                    \n",
      "INFO:train:E:1 (72%), step=9000, loss=0.378                    \n",
      "INFO:train:E:1 (76%), step=9500, loss=0.382                    \n",
      "INFO:train:E:1 (80%), step=10000, loss=0.367                   \n",
      "INFO:train:E:1 (84%), step=10500, loss=0.375                    \n",
      "INFO:train:E:1 (88%), step=11000, loss=0.363                    \n",
      "INFO:train:E:1 (92%), step=11500, loss=0.366                    \n",
      " Epoch 0:  96%|█████████▌| 11983/12500 [00:37<00:01, 412.74it/s]\n",
      "validation:   0%|          | 0/2500 [00:00<?, ?it/s]\u001B[A\n",
      "validation:   3%|▎         | 65/2500 [00:00<00:03, 644.53it/s]\u001B[A\n",
      "validation:   5%|▌         | 130/2500 [00:00<00:03, 623.14it/s]\u001B[A\n",
      "validation:   8%|▊         | 195/2500 [00:00<00:03, 634.20it/s]\u001B[A\n",
      "validation:  11%|█         | 263/2500 [00:00<00:03, 651.07it/s]\u001B[A\n",
      "validation:  13%|█▎        | 329/2500 [00:00<00:03, 653.05it/s]\u001B[A\n",
      "validation:  16%|█▌        | 397/2500 [00:00<00:03, 659.92it/s]\u001B[A\n",
      "validation:  19%|█▊        | 464/2500 [00:00<00:03, 655.98it/s]\u001B[A\n",
      "validation:  21%|██        | 531/2500 [00:00<00:02, 658.74it/s]\u001B[A\n",
      "validation:  24%|██▍       | 597/2500 [00:00<00:02, 655.59it/s]\u001B[A\n",
      "validation:  27%|██▋       | 663/2500 [00:01<00:02, 655.35it/s]\u001B[A\n",
      "validation:  29%|██▉       | 729/2500 [00:01<00:02, 653.15it/s]\u001B[A\n",
      "validation:  32%|███▏      | 795/2500 [00:01<00:02, 650.87it/s]\u001B[A\n",
      "validation:  34%|███▍      | 861/2500 [00:01<00:02, 651.65it/s]\u001B[A\n",
      "validation:  37%|███▋      | 927/2500 [00:01<00:02, 650.58it/s]\u001B[A\n",
      "validation:  40%|███▉      | 993/2500 [00:01<00:02, 647.57it/s]\u001B[A\n",
      "validation:  42%|████▏     | 1058/2500 [00:01<00:02, 645.77it/s]\u001B[A\n",
      "validation:  45%|████▍     | 1124/2500 [00:01<00:02, 649.53it/s]\u001B[A\n",
      "validation:  48%|████▊     | 1190/2500 [00:01<00:02, 651.38it/s]\u001B[A\n",
      "validation:  50%|█████     | 1256/2500 [00:01<00:01, 649.72it/s]\u001B[A\n",
      "validation:  53%|█████▎    | 1323/2500 [00:02<00:01, 654.78it/s]\u001B[A\n",
      "validation:  56%|█████▌    | 1389/2500 [00:02<00:01, 640.13it/s]\u001B[A\n",
      "validation:  58%|█████▊    | 1454/2500 [00:02<00:01, 632.71it/s]\u001B[A\n",
      "validation:  61%|██████    | 1519/2500 [00:02<00:01, 635.27it/s]\u001B[A\n",
      "validation:  63%|██████▎   | 1585/2500 [00:02<00:01, 642.42it/s]\u001B[A\n",
      "validation:  66%|██████▌   | 1651/2500 [00:02<00:01, 644.68it/s]\u001B[A\n",
      "validation:  69%|██████▊   | 1716/2500 [00:02<00:01, 643.74it/s]\u001B[A\n",
      "validation:  71%|███████▏  | 1782/2500 [00:02<00:01, 646.34it/s]\u001B[A\n",
      "validation:  74%|███████▍  | 1847/2500 [00:02<00:01, 620.39it/s]\u001B[A\n",
      "validation:  76%|███████▋  | 1912/2500 [00:02<00:00, 628.45it/s]\u001B[A\n",
      "validation:  79%|███████▉  | 1977/2500 [00:03<00:00, 632.39it/s]\u001B[A\n",
      "validation:  82%|████████▏ | 2041/2500 [00:03<00:00, 618.10it/s]\u001B[A\n",
      "validation:  84%|████████▍ | 2104/2500 [00:03<00:00, 620.17it/s]\u001B[A\n",
      "validation:  87%|████████▋ | 2174/2500 [00:03<00:00, 642.60it/s]\u001B[A\n",
      "validation:  90%|████████▉ | 2246/2500 [00:03<00:00, 664.03it/s]\u001B[A\n",
      "validation:  93%|█████████▎| 2319/2500 [00:03<00:00, 682.69it/s]\u001B[A\n",
      "validation:  96%|█████████▌| 2388/2500 [00:03<00:00, 683.91it/s]\u001B[A\n",
      "validation: 100%|██████████| 2500/2500 [00:03<00:00, 649.77it/s]\u001B[A\n",
      "INFO:train:Validation at 48000 step: acc: 0.47 , f1-macro: 0.47 , f1-micro: 0.47 , val_loss: 1.46\n",
      "INFO:train:E:1 (96%), step=12000, loss=0.372                    \n",
      "INFO:train:E:1 (100%), step=12500, loss=0.355                   \n",
      " Epoch 0: 100%|██████████| 12500/12500 [00:43<00:00, 290.44it/s]\n",
      "INFO:train:E:2 (4%), step=500, loss=0.362                     \n",
      "INFO:train:E:2 (8%), step=1000, loss=0.349                    \n",
      "INFO:train:E:2 (12%), step=1500, loss=0.349                    \n",
      "INFO:train:E:2 (16%), step=2000, loss=0.345                    \n",
      "INFO:train:E:2 (20%), step=2500, loss=0.338                    \n",
      "INFO:train:E:2 (24%), step=3000, loss=0.348                    \n",
      " Epoch 1:  27%|██▋       | 3346/12500 [00:09<00:26, 350.72it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/vv/h7pd2fgx3fx5y6vk5nz1j2msgf0ysm/T/ipykernel_84141/3716089707.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mtrainer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/code/repos/readable_implementations/src/readable_implementations/utils/trainer.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     72\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     73\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0moptimizer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mzero_grad\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 74\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrain\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     75\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0moptimizer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mzero_grad\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     76\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/code/repos/readable_implementations/src/readable_implementations/utils/trainer.py\u001B[0m in \u001B[0;36mtrain\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     78\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrain\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     79\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mepoch\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmax_epochs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 80\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrain_one_epoch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mepoch\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     81\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     82\u001B[0m     def train_one_epoch(\n",
      "\u001B[0;32m~/code/repos/readable_implementations/src/readable_implementations/utils/trainer.py\u001B[0m in \u001B[0;36mtrain_one_epoch\u001B[0;34m(self, epoch_idx)\u001B[0m\n\u001B[1;32m     87\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mglobal_step\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbatch_size\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     88\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0moptimizer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mzero_grad\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 89\u001B[0;31m             \u001B[0mloss_step\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrain_step\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbatch\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     90\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0moptimizer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     91\u001B[0m             \u001B[0mloss_per_logging\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0mloss_step\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mitem\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/code/repos/readable_implementations/src/readable_implementations/utils/trainer.py\u001B[0m in \u001B[0;36mtrain_step\u001B[0;34m(self, batch)\u001B[0m\n\u001B[1;32m    118\u001B[0m         \u001B[0mout\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    119\u001B[0m         \u001B[0mloss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mloss_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mout\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtarget\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 120\u001B[0;31m         \u001B[0mloss\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    121\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mloss\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    122\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.pyenv/versions/readable_implementations/lib/python3.7/site-packages/torch/_tensor.py\u001B[0m in \u001B[0;36mbackward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    361\u001B[0m                 \u001B[0mcreate_graph\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mcreate_graph\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    362\u001B[0m                 inputs=inputs)\n\u001B[0;32m--> 363\u001B[0;31m         \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mautograd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgradient\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    364\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    365\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mregister_hook\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mhook\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.pyenv/versions/readable_implementations/lib/python3.7/site-packages/torch/autograd/__init__.py\u001B[0m in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    173\u001B[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001B[1;32m    174\u001B[0m         \u001B[0mtensors\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgrad_tensors_\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 175\u001B[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001B[0m\u001B[1;32m    176\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    177\u001B[0m def grad(\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "trainer.fit()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}